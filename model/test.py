from model.preprocess import word_level_tokenize

z = word_level_tokenize("I'm OK, are you OK? I am in China, I bought china.")
print(z)